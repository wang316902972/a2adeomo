"""
FastAPI æœåŠ¡ï¼šSQL ä¼˜åŒ–å®¡æ ¸ç³»ç»Ÿ API (å• Agent + SSH æ¶æ„)
åŸºäºå• Agent æ¶æ„å’Œ SSH è®¤è¯çš„ SQL ä¼˜åŒ–å’Œå®¡æ ¸åŠŸèƒ½

å¯åŠ¨æœåŠ¡:
uvicorn fastapi_service:app --host 0.0.0.0 --port 8000 --reload

API æ–‡æ¡£:
http://localhost:8000/docs

æ¶æ„ç‰¹ç‚¹:
- å•ä¸€ç»¼åˆ SQL ä¸“å®¶ Agent
- SSH æ–¹å¼è®¿é—® GitHubï¼Œæ›´å®‰å…¨çš„è®¤è¯
- ç®€åŒ–çš„å·¥ä½œæµç¨‹ï¼Œé«˜æ•ˆæ‰§è¡Œ
- é›†æˆåˆ†æã€ä¼˜åŒ–ã€æŠ¥å‘Šäºä¸€ä½“

ç¯å¢ƒå˜é‡é…ç½®:
GITHUB_SSH_KEY_PATH      - SSH ç§é’¥æ–‡ä»¶è·¯å¾„
GITHUB_SSH_KEY_CONTENT   - SSH ç§é’¥å†…å®¹ (å¯é€‰)
GITHUB_USER              - Git ç”¨æˆ·å
GITHUB_EMAIL             - Git é‚®ç®±åœ°å€
GITHUB_WEBHOOK_SECRET    - Webhook å¯†é’¥
OPENAI_API_KEY           - LLM API å¯†é’¥
OPENAI_BASE_URL          - LLM åŸºç¡€ URL
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, List
import asyncio
import json
import logging
from datetime import datetime
import uuid
import hmac
import hashlib
import httpx
import os
import re
import subprocess
import tempfile
import shutil
from pathlib import Path

# å¯¼å…¥å• Agent SQL ä¼˜åŒ–ç»„ä»¶
from optimize_sql import SQLOptimizerSingle

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="SQL ä¼˜åŒ–å®¡æ ¸ç³»ç»Ÿ API",
    description="åŸºäºå• Agent æ¶æ„çš„ SQL ä¼˜åŒ–å’Œå®¡æ ¸æœåŠ¡",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥è®¾ç½®å…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡å­˜å‚¨ SQL ä¼˜åŒ–å™¨å®ä¾‹
sql_optimizer_instance = None

# Pydantic æ¨¡å‹å®šä¹‰
class SQLOptimizationRequest(BaseModel):
    """SQL ä¼˜åŒ–è¯·æ±‚æ¨¡å‹"""
    sql_query: str = Field(..., description="è¦ä¼˜åŒ–çš„ SQL æŸ¥è¯¢è¯­å¥", min_length=10, max_length=10000)
    optimization_level: Optional[str] = Field("standard", description="ä¼˜åŒ–çº§åˆ«", pattern="^(basic|standard|aggressive)$")
    include_review: Optional[bool] = Field(True, description="æ˜¯å¦åŒ…å«å®¡æ ¸æ­¥éª¤")

class SQLOptimizationResponse(BaseModel):
    """SQL ä¼˜åŒ–å“åº”æ¨¡å‹"""
    request_id: str
    status: str
    message: str
    timestamp: str
    optimization_result: Optional[Dict[str, Any]] = None
    review_result: Optional[Dict[str, Any]] = None
    final_status: Optional[str] = None
    processing_time: Optional[float] = None

class TaskStatus(BaseModel):
    """ä»»åŠ¡çŠ¶æ€æ¨¡å‹"""
    task_id: str
    status: str
    message: str
    progress: Optional[float] = None
    created_at: str
    updated_at: str
    result: Optional[Dict[str, Any]] = None

class GitHubWebhookRequest(BaseModel):
    """GitHub Webhook è¯·æ±‚æ¨¡å‹"""
    ref: Optional[str] = None
    repository: Optional[Dict[str, Any]] = None
    commits: Optional[List[Dict[str, Any]]] = None
    pusher: Optional[Dict[str, Any]] = None
    head_commit: Optional[Dict[str, Any]] = None
    sender: Optional[Dict[str, Any]] = None

class SQLReviewResult(BaseModel):
    """SQL å®¡æ ¸ç»“æœæ¨¡å‹"""
    file_path: str
    status: str
    issues: List[str]
    optimizations: Optional[List[str]] = None
    optimized_sql: Optional[str] = None
    severity: str  # 'low', 'medium', 'high', 'critical'

class WebhookResponse(BaseModel):
    """Webhook å“åº”æ¨¡å‹"""
    webhook_id: str
    status: str
    message: str
    timestamp: str
    repository: Optional[str] = None
    commit: Optional[str] = None
    sql_files_found: int
    reviews: Optional[List[SQLReviewResult]] = None

# å†…å­˜å­˜å‚¨ä»»åŠ¡çŠ¶æ€ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨ Redisï¼‰
task_store: Dict[str, TaskStatus] = {}

# GitHub webhook é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
GITHUB_WEBHOOK_SECRET = os.getenv("GITHUB_WEBHOOK_SECRET", "")
# SSH é…ç½®
GITHUB_SSH_KEY_PATH = os.getenv("GITHUB_SSH_KEY_PATH", "")  # SSH ç§é’¥æ–‡ä»¶è·¯å¾„
GITHUB_SSH_KEY_CONTENT = os.getenv("GITHUB_SSH_KEY_CONTENT", "")  # SSH ç§é’¥å†…å®¹ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨æ–‡ä»¶è·¯å¾„ï¼‰
GITHUB_KNOWN_HOSTS_PATH = os.getenv("GITHUB_KNOWN_HOSTS_PATH", "/tmp/known_hosts")  # SSH known_hosts æ–‡ä»¶è·¯å¾„
GITHUB_USER = os.getenv("GITHUB_USER", "git")  # Git ç”¨æˆ·å
GITHUB_EMAIL = os.getenv("GITHUB_EMAIL", "")  # Git é‚®ç®±ï¼ˆç”¨äº commit ç­¾åï¼‰

# å­˜å‚¨ webhook å¤„ç†å†å²
webhook_history: Dict[str, WebhookResponse] = {}

# SSH é…ç½®å…¨å±€å˜é‡
ssh_configured = False

async def setup_ssh_config():
    """è®¾ç½® SSH é…ç½®"""
    global ssh_configured
    try:
        # æ£€æŸ¥ SSH å¯†é’¥é…ç½®
        ssh_key_path = GITHUB_SSH_KEY_PATH or ""
        ssh_key_content = GITHUB_SSH_KEY_CONTENT or ""

        if not ssh_key_path and not ssh_key_content:
            logger.warning("âŒ æœªé…ç½® GitHub SSH å¯†é’¥ï¼Œè¯·è®¾ç½® GITHUB_SSH_KEY_PATH æˆ– GITHUB_SSH_KEY_CONTENT ç¯å¢ƒå˜é‡")
            return False

        ssh_configured = True
        logger.info("âœ… SSH é…ç½®åˆå§‹åŒ–æˆåŠŸ")
        return True

    except Exception as e:
        logger.error(f"âŒ SSH é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")
        ssh_configured = False
        return False

# å¯åŠ¨æ—¶åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å• Agent SQL ä¼˜åŒ–å™¨å’Œ SSH é…ç½®"""
    global sql_optimizer_instance
    try:
        # åˆå§‹åŒ– SSH é…ç½®
        await setup_ssh_config()

        # åˆå§‹åŒ–å• Agent SQL ä¼˜åŒ–å™¨
        logger.info("æ­£åœ¨åˆå§‹åŒ–å• Agent SQL ä¼˜åŒ–å™¨...")
        sql_optimizer_instance = SQLOptimizerSingle()
        logger.info("âœ… å• Agent SQL ä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ å• Agent SQL ä¼˜åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        sql_optimizer_instance = None

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "SQL ä¼˜åŒ–å®¡æ ¸ç³»ç»Ÿ API (å• Agent æ¶æ„)",
        "version": "2.0.0",
        "status": "running",
        "architecture": "single_agent",
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "optimize_sql": "/api/optimize",
            "task_status": "/api/task/{task_id}",
            "health": "/api/health",
            "docs": "/docs"
        }
    }

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "sql_optimizer": "initialized" if sql_optimizer_instance else "not_initialized",
        "architecture": "single_agent",
        "ssh_configured": ssh_configured,
        "github_auth_method": get_github_auth_method()
    }

def get_github_auth_method() -> str:
    """è·å– GitHub è®¤è¯æ–¹æ³•"""
    if os.getenv("GITHUB_TOKEN"):
        return "token"
    elif ssh_configured:
        return "ssh"
    else:
        return "not_configured"

@app.post("/api/optimize", response_model=SQLOptimizationResponse)
async def optimize_sql_endpoint(request: SQLOptimizationRequest, background_tasks: BackgroundTasks):
    """
    ä¼˜åŒ– SQL æŸ¥è¯¢ (å• Agent æ¶æ„)

    - **sql_query**: è¦ä¼˜åŒ–çš„ SQL è¯­å¥
    - **optimization_level**: ä¼˜åŒ–çº§åˆ« (basic/standard/aggressive) - å½“å‰ç‰ˆæœ¬å¿½ç•¥ï¼Œä½¿ç”¨ç»Ÿä¸€ä¼˜åŒ–ç­–ç•¥
    - **include_review**: æ˜¯å¦åŒ…å«å®¡æ ¸æ­¥éª¤ - å½“å‰ç‰ˆæœ¬å• Agent å·²åŒ…å«ç»¼åˆåˆ†æ
    """
    if not sql_optimizer_instance:
        raise HTTPException(
            status_code=503,
            detail="SQL ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–ï¼ŒæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        )

    # ç”Ÿæˆè¯·æ±‚ ID
    request_id = str(uuid.uuid4())
    start_time = datetime.now()

    try:
        logger.info(f"æ”¶åˆ° SQL ä¼˜åŒ–è¯·æ±‚: {request_id}")

        # å• Agent æ‰§è¡Œå®Œæ•´ä¼˜åŒ–åˆ†æ
        optimization_result = sql_optimizer_instance.optimize_sql(request.sql_query)

        # å• Agent å·²ç»åŒ…å«å®Œæ•´çš„åˆ†æå’Œä¼˜åŒ–ï¼Œæ— éœ€é¢å¤–çš„å®¡æ ¸æ­¥éª¤
        review_result = None
        final_status = "OPTIMIZED_BY_SINGLE_AGENT"

        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (datetime.now() - start_time).total_seconds()

        response = SQLOptimizationResponse(
            request_id=request_id,
            status="success",
            message="SQL ä¼˜åŒ–å®Œæˆ (å• Agent ç»¼åˆåˆ†æ)",
            timestamp=datetime.now().isoformat(),
            optimization_result=optimization_result,
            review_result=review_result,
            final_status=final_status,
            processing_time=processing_time
        )

        logger.info(f"SQL ä¼˜åŒ–å®Œæˆ: {request_id}, è€—æ—¶: {processing_time:.2f}s")
        return response

    except Exception as e:
        logger.error(f"SQL ä¼˜åŒ–å¤±è´¥: {request_id}, é”™è¯¯: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"SQL ä¼˜åŒ–å¤±è´¥: {str(e)}"
        )

@app.post("/api/optimize-async")
async def optimize_sql_async(request: SQLOptimizationRequest, background_tasks: BackgroundTasks):
    """
    å¼‚æ­¥ä¼˜åŒ– SQL æŸ¥è¯¢ï¼ˆé€‚ç”¨äºé•¿æ—¶é—´è¿è¡Œçš„ä¼˜åŒ–ä»»åŠ¡ï¼‰- å• Agent æ¶æ„

    è¿”å›ä»»åŠ¡ IDï¼Œå¯ä»¥é€šè¿‡ /api/task/{task_id} æŸ¥è¯¢çŠ¶æ€
    """
    if not sql_optimizer_instance:
        raise HTTPException(
            status_code=503,
            detail="SQL ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–ï¼ŒæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        )

    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = str(uuid.uuid4())

    # åˆ›å»ºä»»åŠ¡çŠ¶æ€
    task_status = TaskStatus(
        task_id=task_id,
        status="pending",
        message="ä»»åŠ¡å·²æäº¤ï¼Œç­‰å¾…å• Agent å¤„ç†",
        progress=0.0,
        created_at=datetime.now().isoformat(),
        updated_at=datetime.now().isoformat()
    )
    task_store[task_id] = task_status

    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(process_optimization_task_single_agent, task_id, request)

    return {
        "task_id": task_id,
        "status": "submitted",
        "message": "ä¼˜åŒ–ä»»åŠ¡å·²æäº¤ (å• Agent å¤„ç†)",
        "timestamp": datetime.now().isoformat()
    }

async def process_optimization_task_single_agent(task_id: str, request: SQLOptimizationRequest):
    """åå°å¤„ç†ä¼˜åŒ–ä»»åŠ¡ - å• Agent æ¶æ„"""
    try:
        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        task_status = task_store[task_id]
        task_status.status = "processing"
        task_status.message = "å• Agent æ­£åœ¨æ‰§è¡Œ SQL ä¼˜åŒ–åˆ†æ..."
        task_status.progress = 50.0
        task_status.updated_at = datetime.now().isoformat()

        # å• Agent æ‰§è¡Œå®Œæ•´ä¼˜åŒ–åˆ†æ
        optimization_result = sql_optimizer_instance.optimize_sql(request.sql_query)

        # æ›´æ–°ä¸ºå®ŒæˆçŠ¶æ€
        task_status.status = "completed"
        task_status.message = "å• Agent ä¼˜åŒ–åˆ†æå®Œæˆ"
        task_status.progress = 100.0
        task_status.updated_at = datetime.now().isoformat()
        task_status.result = {
            "optimization": optimization_result,
            "review": None,  # å• Agent å·²åŒ…å«ç»¼åˆåˆ†æï¼Œæ— éœ€å•ç‹¬å®¡æ ¸
            "final_status": "OPTIMIZED_BY_SINGLE_AGENT"
        }

    except Exception as e:
        logger.error(f"å• Agent åå°ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
        # æ›´æ–°ä¸ºå¤±è´¥çŠ¶æ€
        task_status = task_store[task_id]
        task_status.status = "failed"
        task_status.message = f"å• Agent ä»»åŠ¡å¤±è´¥: {str(e)}"
        task_status.updated_at = datetime.now().isoformat()

@app.get("/api/task/{task_id}", response_model=TaskStatus)
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_id not in task_store:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    return task_store[task_id]

@app.get("/api/tasks")
async def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
    return {
        "tasks": list(task_store.values()),
        "total": len(task_store)
    }

@app.delete("/api/task/{task_id}")
async def delete_task(task_id: str):
    """åˆ é™¤ä»»åŠ¡"""
    if task_id not in task_store:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    del task_store[task_id]
    return {"message": "ä»»åŠ¡å·²åˆ é™¤"}

# ============================================================================
# GitLab Webhook ç›¸å…³åŠŸèƒ½
# ============================================================================

def verify_gitlab_signature(payload_body: bytes, signature_header: str, token_header: str = None) -> bool:
    """éªŒè¯ GitLab webhook ç­¾å"""
    if not GITHUB_WEBHOOK_SECRET:  # é‡ç”¨ç›¸åŒçš„ç¯å¢ƒå˜é‡ï¼Œä½†ç”¨äº GitLab
        logger.warning("âš ï¸ æœªè®¾ç½® GITHUB_WEBHOOK_SECRETï¼Œè·³è¿‡ç­¾åéªŒè¯ (ä»…ç”¨äºæµ‹è¯•ç¯å¢ƒ)")
        logger.info("ğŸ’¡ ç”Ÿäº§ç¯å¢ƒè¯·è®¾ç½® GITHUB_WEBHOOK_SECRET ç¯å¢ƒå˜é‡ä»¥ç¡®ä¿å®‰å…¨æ€§")
        return True

    try:
        # GitLab æ”¯æŒå¤šç§éªŒè¯æ–¹å¼
        # 1. Token éªŒè¯ (æ¨è)
        if token_header:
            expected_token = GITHUB_WEBHOOK_SECRET
            if token_header == expected_token:
                logger.info("âœ… GitLab Token éªŒè¯æˆåŠŸ")
                return True
            else:
                logger.error("âŒ GitLab Token éªŒè¯å¤±è´¥")
                logger.error(f"Expected: {expected_token}")
                logger.error(f"Received: {token_header}")
                return False

        # 2. X-Gitlab-Token header éªŒè¯
        gitlab_token_header = None  # éœ€è¦ä»è¯·æ±‚å¤´ä¸­è·å–

        # 3. Signature éªŒè¯ (å¦‚æœä½¿ç”¨ secret)
        if signature_header:
            # GitLab çš„ç­¾åæ ¼å¼å¯èƒ½æ˜¯: sha256=xxxxx
            if signature_header.startswith('sha256='):
                hash_algorithm, gitlab_signature = signature_header.split('=', 1)

                if hash_algorithm == 'sha256':
                    # è®¡ç®—é¢„æœŸçš„ç­¾å
                    mac = hmac.new(
                        GITHUB_WEBHOOK_SECRET.encode('utf-8'),
                        msg=payload_body,
                        digestmod=hashlib.sha256
                    )
                    expected_signature = mac.hexdigest()

                    # ä½¿ç”¨æ’å®šæ—¶é—´æ¯”è¾ƒé˜²æ­¢æ—¶åºæ”»å‡»
                    is_valid = hmac.compare_digest(expected_signature, gitlab_signature)

                    if not is_valid:
                        logger.error("âŒ GitLab Webhook ç­¾åéªŒè¯å¤±è´¥")
                        logger.error(f"Expected: sha256={expected_signature}")
                        logger.error(f"Received: {signature_header}")
                    else:
                        logger.info("âœ… GitLab Webhook ç­¾åéªŒè¯æˆåŠŸ")

                    return is_valid
                else:
                    logger.error(f"âŒ ä¸æ”¯æŒçš„å“ˆå¸Œç®—æ³•: {hash_algorithm}")
                    return False
            else:
                logger.error("âŒ GitLab ç­¾åæ ¼å¼é”™è¯¯ï¼Œåº”ä»¥ 'sha256=' å¼€å¤´")
                return False

        # å¦‚æœæ²¡æœ‰æä¾›ä»»ä½•éªŒè¯ä¿¡æ¯
        logger.warning("âš ï¸ æœªæä¾› GitLab webhook éªŒè¯ä¿¡æ¯")
        return True  # æµ‹è¯•ç¯å¢ƒä¸‹å…è®¸é€šè¿‡

    except Exception as e:
        logger.error(f"âŒ GitLab ç­¾åéªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

def extract_sql_files(commits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä»æäº¤ä¸­æå– SQL æ–‡ä»¶ (æ”¯æŒ GitLab webhook æ ¼å¼)"""
    sql_files = []

    logger.info(f"å¼€å§‹å¤„ç† {len(commits)} ä¸ªæäº¤")

    for commit in commits:
        # æ£€æŸ¥ commit æ˜¯å¦ä¸ºå­—å…¸ç±»å‹
        if not isinstance(commit, dict):
            logger.error(f"Commit ä¸æ˜¯å­—å…¸ç±»å‹: {type(commit)}")
            continue

        commit_id = commit.get('id', '')
        commit_message = commit.get('message', '')

        logger.info(f"å¤„ç† commit: {commit_id[:8]} - {commit_message[:50]}")

        # GitLab webhook ä¸­æ–‡ä»¶å˜æ›´ä¿¡æ¯
        # GitLab ä½¿ç”¨ 'added', 'modified', 'removed' å­—æ®µ
        added = commit.get('added', [])
        modified = commit.get('modified', [])
        removed = commit.get('removed', [])

        logger.info(f"æ–‡ä»¶å˜æ›´ç»Ÿè®¡ - æ–°å¢: {len(added)}, ä¿®æ”¹: {len(modified)}, åˆ é™¤: {len(removed)}")

        # åˆå¹¶æ‰€æœ‰å˜æ›´çš„æ–‡ä»¶
        all_changed_files = []

        # å¤„ç†æ·»åŠ çš„æ–‡ä»¶
        for file_info in added:
            if isinstance(file_info, dict):
                # GitLab å¯èƒ½è¿”å›æ–‡ä»¶å¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²
                file_path = file_info.get('path', '')
                all_changed_files.append({'path': file_path, 'action': 'added'})
            else:
                all_changed_files.append({'path': file_info, 'action': 'added'})

        # å¤„ç†ä¿®æ”¹çš„æ–‡ä»¶
        for file_info in modified:
            if isinstance(file_info, dict):
                file_path = file_info.get('path', '')
                all_changed_files.append({'path': file_path, 'action': 'modified'})
            else:
                all_changed_files.append({'path': file_info, 'action': 'modified'})

        # æå– SQL æ–‡ä»¶
        for file_info in all_changed_files:
            file_path = file_info.get('path', file_info if isinstance(file_info, str) else '')

            if file_path.lower().endswith('.sql'):
                sql_files.append({
                    'file_path': file_path,
                    'commit_id': commit_id,
                    'commit_message': commit_message,
                    'action': file_info.get('action', 'modified')
                })
                logger.info(f"å‘ç° SQL æ–‡ä»¶: {file_path}")

    logger.info(f"æ€»å…±å‘ç° {len(sql_files)} ä¸ª SQL æ–‡ä»¶")
    return sql_files

async def fetch_file_content(repo_full_name: str, file_path: str, commit_sha: str) -> Optional[str]:
    """é€šè¿‡ SSH ä» GitLab è·å–æ–‡ä»¶å†…å®¹"""
    if not ssh_configured:
        logger.warning("SSH é…ç½®æœªå®Œæˆï¼Œæ— æ³•è·å–æ–‡ä»¶å†…å®¹")
        return None

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    try:
        # è®¾ç½® SSH ç¯å¢ƒ
        env = os.environ.copy()
        ssh_command_parts = []

        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„å¯†é’¥å†…å®¹
        ssh_key_content = GITHUB_SSH_KEY_CONTENT
            # ä½¿ç”¨é»˜è®¤çš„ SSH é…ç½® (~/.ssh/id_rsa)
        default_key = Path.home() / ".ssh" / "id_rsa"
        if default_key.exists():
            ssh_command_parts.append(f"-i {default_key}")
            logger.info(f"ä½¿ç”¨é»˜è®¤ SSH å¯†é’¥: {default_key}")
        else:
            logger.warning("æœªæ‰¾åˆ° SSH å¯†é’¥ï¼Œä½¿ç”¨é»˜è®¤ SSH é…ç½®")
                

        # æ·»åŠ  SSH é…ç½®é€‰é¡¹
        ssh_command_parts.extend([
            "-o StrictHostKeyChecking=no",
            "-o UserKnownHostsFile=/dev/null",
            "-o LogLevel=ERROR"
        ])

        # æ„å»º SSH å‘½ä»¤
        if ssh_command_parts:
            ssh_command = f"ssh {' '.join(ssh_command_parts)}"
            env['GIT_SSH_COMMAND'] = ssh_command
            logger.info(f"SSH å‘½ä»¤: {ssh_command}")

        # è®¾ç½® Git ç”¨æˆ·ä¿¡æ¯
        env['GIT_AUTHOR_NAME'] = GITHUB_USER
        env['GIT_AUTHOR_EMAIL'] = GITHUB_EMAIL or "sql-optimizer@example.com"
        env['GIT_COMMITTER_NAME'] = GITHUB_USER
        env['GIT_COMMITTER_EMAIL'] = GITHUB_EMAIL or "sql-optimizer@example.com"

        repo_url = f"ssh://git@git.nd.com.cn:10022/data-tech/monitor/{repo_full_name}.git"
      
        logger.info(f"å°è¯•å…‹éš†ä»“åº“: {repo_url}")
        logger.info(f"ä»“åº“å®Œæ•´åç§°: {repo_full_name}")

        # ä½¿ç”¨ä¸´æ—¶ç›®å½•ï¼Œé¿å…è·¯å¾„å†²çª
        import tempfile
        import shutil
        
        temp_dir = tempfile.mkdtemp(prefix="git_clone_")
        clone_path = Path(temp_dir) / "repo"
        logger.info(f"ä½¿ç”¨ä¸´æ—¶ç›®å½•: {clone_path}")

        try:
            # å…‹éš†ç‰¹å®š commit
            clone_cmd = [
                'git', 'clone', '--depth', '1',
                '--no-checkout', repo_url, str(clone_path)
            ]

            logger.info(f"æ‰§è¡Œå…‹éš†å‘½ä»¤: {' '.join(clone_cmd)}")
            result = subprocess.run(
                clone_cmd,
                capture_output=True,
                text=True,
                env=env,
                timeout=60
            )

            if result.returncode != 0:
                logger.error(f"Git å…‹éš†å¤±è´¥: {result.stderr}")
                logger.error(f"å…‹éš†å‘½ä»¤è¾“å‡º: {result.stdout}")
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                shutil.rmtree(temp_dir, ignore_errors=True)
                return None

            logger.info("ä»“åº“å…‹éš†æˆåŠŸ")

            # åˆ‡æ¢åˆ°æŒ‡å®š commit å¹¶æ£€å‡ºæ–‡ä»¶
            original_cwd = os.getcwd()
            try:
                os.chdir(clone_path)

                # æ£€å‡ºç‰¹å®š commit
                checkout_cmd = ['git', 'checkout', commit_sha, '--', file_path]
                logger.info(f"æ‰§è¡Œæ£€å‡ºå‘½ä»¤: {' '.join(checkout_cmd)}")

                result = subprocess.run(
                    checkout_cmd,
                    capture_output=True,
                    text=True,
                    env=env,
                    timeout=30
                )

                if result.returncode != 0:
                    logger.error(f"Git æ£€å‡ºå¤±è´¥: {file_path}, é”™è¯¯: {result.stderr}")
                    return None

                logger.info("æ–‡ä»¶æ£€å‡ºæˆåŠŸ")

                # è¯»å–æ–‡ä»¶å†…å®¹
                file_full_path = clone_path / file_path
                if file_full_path.exists():
                    content = file_full_path.read_text(encoding='utf-8', errors='ignore')
                    logger.info(f"æˆåŠŸè¯»å–æ–‡ä»¶å†…å®¹ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                    return content
                else:
                    logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    return None

            finally:
                # æ¢å¤åŸå§‹å·¥ä½œç›®å½•
                os.chdir(original_cwd)
                
        except subprocess.TimeoutExpired:
            logger.error(f"Git æ“ä½œè¶…æ—¶: {file_path}")
            return None
        except Exception as e:
            logger.error(f"é€šè¿‡ SSH è·å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

    except Exception as e:
        logger.error(f"åˆ›å»ºä¸´æ—¶ç›®å½•æˆ–å…‹éš†ä»“åº“å¤±è´¥: {e}")
        return None

async def post_github_comment(repo_full_name: str, commit_sha: str, comment: str) -> bool:
    """åœ¨ Git commit ä¸Šå‘å¸ƒè¯„è®º (æ”¯æŒ SSH æ–¹å¼ï¼Œé€‚ç”¨äº git.nd.com.cn)"""

    # æ³¨æ„ï¼šç”±äºä½¿ç”¨ git.nd.com.cn è€Œé GitHub.comï¼ŒGitHub API ä¸å¯ç”¨
    # ç›´æ¥ä½¿ç”¨ SSH æ–¹å¼åˆ›å»ºå¸¦è¯„è®ºçš„ tag
    logger.info("ä½¿ç”¨ SSH æ–¹å¼åˆ›å»ºè¯„è®º tag (é€‚ç”¨äº git.nd.com.cn)")

    # ä½¿ç”¨ SSH æ–¹å¼åˆ›å»ºå¸¦è¯„è®ºçš„ tag
    if not ssh_configured:
        logger.warning("SSH é…ç½®æœªå®Œæˆä¸”æ—  Tokenï¼Œæ— æ³•å‘å¸ƒè¯„è®º")
        return False

    try:
        # è®¾ç½® SSH ç¯å¢ƒ
        env = os.environ.copy()

        # è®¾ç½® SSH å¯†é’¥
        ssh_key_path = GITHUB_SSH_KEY_PATH
        if ssh_key_path and Path(ssh_key_path).exists():
            env['GIT_SSH_COMMAND'] = f'ssh -i {ssh_key_path} -o StrictHostKeyChecking=no -o UserKnownHostsFile={GITHUB_KNOWN_HOSTS_PATH}'
      
        # è®¾ç½® Git ç”¨æˆ·ä¿¡æ¯
        env['GIT_AUTHOR_NAME'] = GITHUB_USER
        env['GIT_AUTHOR_EMAIL'] = GITHUB_EMAIL or "sql-optimizer@example.com"
        env['GIT_COMMITTER_NAME'] = GITHUB_USER
        env['GIT_COMMITTER_EMAIL'] = GITHUB_EMAIL or "sql-optimizer@example.com"

        repo_url = f"ssh://git@git.nd.com.cn:10022/data-tech/monitor/{repo_full_name}.git"
        clone_path = "/data/optimize_sql/repo"

        # å…‹éš†ä»“åº“
        clone_cmd = ['git', 'clone', repo_url, str(clone_path)]
        result = subprocess.run(
            clone_cmd,
            capture_output=True,
            text=True,
            env=env,
            timeout=60
        )

        if result.returncode != 0:
            logger.error(f"Git å…‹éš†å¤±è´¥: {result.stderr}")
            return False

        os.chdir(clone_path)

        # åˆ›å»ºå¸¦è¯„è®ºçš„ tag ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        tag_name = f"sql-review-{commit_sha[:8]}"
        tag_message = f"SQL ä¼˜åŒ–å®¡æ ¸æŠ¥å‘Š\n\n{comment[:500]}"  # é™åˆ¶é•¿åº¦

        # åˆ›å»º annotated tag
        tag_cmd = ['git', 'tag', '-a', tag_name, commit_sha, '-m', tag_message]
        result = subprocess.run(
            tag_cmd,
            capture_output=True,
            text=True,
            env=env,
            timeout=30
        )

        if result.returncode != 0:
            logger.error(f"Git tag åˆ›å»ºå¤±è´¥: {result.stderr}")
            return False

        # æ¨é€ tag
        push_cmd = ['git', 'push', 'origin', tag_name]
        result = subprocess.run(
            push_cmd,
            capture_output=True,
            text=True,
            env=env,
            timeout=30
        )

        if result.returncode == 0:
            logger.info(f"âœ… é€šè¿‡ SSH åˆ›å»ºè¯„è®º tag: {tag_name}")
            return True
        else:
            logger.error(f"Git push å¤±è´¥: {result.stderr}")
            return False

    except subprocess.TimeoutExpired:
        logger.error("Git æ“ä½œè¶…æ—¶")
        return False
    except Exception as e:
        logger.error(f"SSH æ–¹å¼å‘å¸ƒè¯„è®ºå¤±è´¥: {e}")
        return False

def format_review_comment(reviews: List[SQLReviewResult]) -> str:
    """æ ¼å¼åŒ–å®¡æ ¸ç»“æœä¸º Markdown è¯„è®º"""
    comment_parts = ["## ğŸ” SQL ä»£ç å®¡æ ¸æŠ¥å‘Š\n"]
    
    # ç»Ÿè®¡
    total_files = len(reviews)
    critical_count = sum(1 for r in reviews if r.severity == 'critical')
    high_count = sum(1 for r in reviews if r.severity == 'high')
    medium_count = sum(1 for r in reviews if r.severity == 'medium')
    
    comment_parts.append(f"**æ€»è®¡**: {total_files} ä¸ª SQL æ–‡ä»¶\n")
    
    if critical_count > 0:
        comment_parts.append(f"ğŸš¨ **ä¸¥é‡é—®é¢˜**: {critical_count}\n")
    if high_count > 0:
        comment_parts.append(f"âš ï¸ **é«˜ä¼˜å…ˆçº§**: {high_count}\n")
    if medium_count > 0:
        comment_parts.append(f"ğŸ’¡ **ä¸­ç­‰ä¼˜å…ˆçº§**: {medium_count}\n")
    
    comment_parts.append("\n---\n\n")
    
    # æ¯ä¸ªæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯
    for review in reviews:
        severity_emoji = {
            'critical': 'ğŸš¨',
            'high': 'âš ï¸',
            'medium': 'ğŸ’¡',
            'low': 'âœ…'
        }.get(review.severity, 'ğŸ“')
        
        comment_parts.append(f"### {severity_emoji} {review.file_path}\n\n")
        comment_parts.append(f"**çŠ¶æ€**: {review.status}\n\n")
        
        if review.issues:
            comment_parts.append("**å‘ç°çš„é—®é¢˜**:\n")
            for i, issue in enumerate(review.issues[:5], 1):  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ª
                comment_parts.append(f"{i}. {issue}\n")
            comment_parts.append("\n")
        
        if review.optimizations:
            comment_parts.append("**ä¼˜åŒ–å»ºè®®**:\n")
            for i, opt in enumerate(review.optimizations[:3], 1):  # é™åˆ¶æ˜¾ç¤ºå‰3ä¸ª
                comment_parts.append(f"{i}. {opt}\n")
            comment_parts.append("\n")
        
        if review.optimized_sql:
            comment_parts.append("<details>\n")
            comment_parts.append("<summary>æŸ¥çœ‹ä¼˜åŒ–åçš„ SQL</summary>\n\n")
            comment_parts.append("```sql\n")
            comment_parts.append(review.optimized_sql[:500])  # é™åˆ¶é•¿åº¦
            if len(review.optimized_sql) > 500:
                comment_parts.append("\n... (å·²æˆªæ–­)")
            comment_parts.append("\n```\n")
            comment_parts.append("</details>\n\n")
        
        comment_parts.append("---\n\n")
    
    comment_parts.append("\nğŸ¤– *æ­¤æŠ¥å‘Šç”± SQL ä¼˜åŒ–å®¡æ ¸ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*")
    
    return "".join(comment_parts)

@app.post("/api/webhook/gitlab", response_model=WebhookResponse)
async def gitlab_webhook(
    request: Request,
    background_tasks: BackgroundTasks
):
    """
    GitLab Webhook æ¥å£

    é…ç½®è¯´æ˜:
    1. åœ¨ GitLab é¡¹ç›®è®¾ç½®ä¸­æ·»åŠ  Webhook
    2. URL: http://your-server:8004/api/webhook/gitlab
    3. Secret Token: è®¾ç½®ä¸€ä¸ªå¯†é’¥ï¼ˆä¸ GITHUB_WEBHOOK_SECRET ç¯å¢ƒå˜é‡ä¸€è‡´ï¼‰
    4. è§¦å‘äº‹ä»¶: Push events

    ç¯å¢ƒå˜é‡:
    - GITHUB_WEBHOOK_SECRET: webhook å¯†é’¥ï¼ˆç”¨äºéªŒè¯è¯·æ±‚ï¼‰
    """
    webhook_id = str(uuid.uuid4())

    try:
        # è¯»å–è¯·æ±‚ä½“
        payload_body = await request.body()

        # æ‰‹åŠ¨è·å– GitLab headers
        headers = dict(request.headers)
        x_gitlab_token = headers.get("x-gitlab-token") or headers.get("X-Gitlab-Token")
        x_gitlab_event = headers.get("x-gitlab-event") or headers.get("X-Gitlab-Event")
        x_gitlab_signature = headers.get("x-gitlab-signature") or headers.get("X-Gitlab-Signature")

        logger.info(f"æ”¶åˆ° GitLab webhook è¯·æ±‚ï¼Œäº‹ä»¶: {x_gitlab_event}")
        logger.info(f"Token: {x_gitlab_token is not None}, Signature: {x_gitlab_signature is not None}")

        # éªŒè¯ç­¾åæˆ–token
        if not verify_gitlab_signature(payload_body, x_gitlab_signature, x_gitlab_token):
            logger.warning("GitLab webhook éªŒè¯å¤±è´¥")
            raise HTTPException(status_code=401, detail="Webhook éªŒè¯å¤±è´¥")

        # åªå¤„ç† push äº‹ä»¶
        if x_gitlab_event != "Push Hook":
            logger.info(f"å¿½ç•¥é push äº‹ä»¶: {x_gitlab_event}")
            return WebhookResponse(
                webhook_id=webhook_id,
                status="ignored",
                message=f"ä»…å¤„ç† Push Hook äº‹ä»¶ï¼Œå½“å‰äº‹ä»¶: {x_gitlab_event}",
                timestamp=datetime.now().isoformat(),
                sql_files_found=0
            )
        
        # è§£æ payload
        try:
            payload = json.loads(payload_body)
            logger.info(f"Payload type: {type(payload)}")
            logger.info(f"Payload keys: {payload.keys() if isinstance(payload, dict) else 'Not a dict'}")
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {e}")
            logger.error(f"Payload body: {payload_body[:500]}...")  # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
            raise

        # æå– GitLab ç‰¹æœ‰ä¿¡æ¯
        if not isinstance(payload, dict):
            logger.error(f"Payload ä¸æ˜¯å­—å…¸ç±»å‹: {type(payload)}")
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ webhook payload æ ¼å¼")

        project = payload.get('project', {})
        if not isinstance(project, dict):
            logger.error(f"Project å­—æ®µä¸æ˜¯å­—å…¸ç±»å‹: {type(project)}")
            project = {}

        repo_name = project.get('name', '')  # GitLab é¡¹ç›®åç§°
        namespace = project.get('namespace', {})
        if isinstance(namespace, dict):
            namespace_name = namespace.get('name', '')
            repo_full_name = f"{namespace_name}/{repo_name}" if namespace_name else repo_name
        else:
            repo_full_name = repo_name

        # GitLab çš„ commits ç»“æ„ä¸ GitHub ç•¥æœ‰ä¸åŒ
        commits = payload.get('commits', [])
        if not isinstance(commits, list):
            logger.error(f"Commits å­—æ®µä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(commits)}")
            commits = []

        if not commits:
            logger.info("æ²¡æœ‰æäº¤ä¿¡æ¯")
            return WebhookResponse(
                webhook_id=webhook_id,
                status="no_commits",
                message="æ²¡æœ‰æ‰¾åˆ°æäº¤ä¿¡æ¯",
                timestamp=datetime.now().isoformat(),
                repository=repo_full_name,
                sql_files_found=0
            )
        
        # æå– SQL æ–‡ä»¶
        sql_files = extract_sql_files(commits)

        if not sql_files:
            logger.info("æ²¡æœ‰å‘ç° SQL æ–‡ä»¶å˜æ›´")
            return WebhookResponse(
                webhook_id=webhook_id,
                status="no_sql_files",
                message="æ²¡æœ‰å‘ç° SQL æ–‡ä»¶å˜æ›´",
                timestamp=datetime.now().isoformat(),
                repository=repo_full_name,
                commit=commits[0].get('id', '') if commits else '',
                sql_files_found=0
            )

        logger.info(f"å‘ç° {len(sql_files)} ä¸ª SQL æ–‡ä»¶éœ€è¦å®¡æ ¸")

        # æäº¤åå°ä»»åŠ¡è¿›è¡Œå®¡æ ¸
        background_tasks.add_task(
            process_sql_reviews_single_agent,
            webhook_id,
            repo_full_name,
            sql_files,
            commits[0].get('id', '') if commits else ''
        )

        response = WebhookResponse(
            webhook_id=webhook_id,
            status="processing",
            message=f"å‘ç° {len(sql_files)} ä¸ª SQL æ–‡ä»¶ï¼Œæ­£åœ¨è¿›è¡Œå®¡æ ¸",
            timestamp=datetime.now().isoformat(),
            repository=repo_full_name,
            commit=commits[0].get('id', '') if commits else '',
            sql_files_found=len(sql_files)
        )

        # ä¿å­˜åˆ°å†å²è®°å½•
        webhook_history[webhook_id] = response

        return response

    except json.JSONDecodeError:
        logger.error("æ— æ³•è§£æ JSON payload")
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ JSON payload")
    except Exception as e:
        logger.error(f"å¤„ç† GitLab webhook å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¤„ç† webhook å¤±è´¥: {str(e)}")

# ä¿ç•™ GitHub webhook ç«¯ç‚¹ä½œä¸ºå¤‡ç”¨ï¼Œä½†é‡å®šå‘åˆ° GitLab å¤„ç†
@app.post("/api/webhook/github", response_model=WebhookResponse)
async def github_webhook_fallback(request: Request, background_tasks: BackgroundTasks):
    """GitHub Webhook å¤‡ç”¨ç«¯ç‚¹ï¼Œé‡å®šå‘åˆ° GitLab å¤„ç†"""
    logger.info("æ”¶åˆ° GitHub webhook è¯·æ±‚ï¼Œä½¿ç”¨ GitLab å¤„ç†é€»è¾‘")
    return await gitlab_webhook(request, background_tasks)

async def process_sql_reviews_single_agent(webhook_id: str, repo_full_name: str, sql_files: List[Dict[str, Any]], commit_sha: str):
    """åå°å¤„ç† SQL æ–‡ä»¶å®¡æ ¸ - å• Agent æ¶æ„"""
    try:
        reviews = []

        for sql_file in sql_files:
            file_path = sql_file['file_path']
            logger.info(f"å• Agent å®¡æ ¸æ–‡ä»¶: {file_path}")

            # è·å–æ–‡ä»¶å†…å®¹
            sql_content = await fetch_file_content(repo_full_name, file_path, commit_sha)

            if not sql_content:
                reviews.append(SQLReviewResult(
                    file_path=file_path,
                    status="error",
                    issues=["æ— æ³•è·å–æ–‡ä»¶å†…å®¹"],
                    severity="medium"
                ))
                continue

            # è°ƒç”¨å• Agent SQL ä¼˜åŒ–æœåŠ¡
            try:
                if sql_optimizer_instance:
                    optimization_result = sql_optimizer_instance.optimize_sql(sql_content)

                    # æå–é—®é¢˜å’Œä¼˜åŒ–å»ºè®®
                    issues = optimization_result.get("issues_found", [])
                    optimizations = optimization_result.get("optimizations_applied", [])
                    optimized_sql = optimization_result.get("optimized_sql", "")

                    # ç¡®å®šä¸¥é‡ç¨‹åº¦
                    severity = "low"
                    if any(keyword in str(issues).lower() for keyword in ['critical', 'ä¸¥é‡', 'error']):
                        severity = "critical"
                    elif any(keyword in str(issues).lower() for keyword in ['warning', 'è­¦å‘Š', 'high']):
                        severity = "high"
                    elif len(issues) > 3:
                        severity = "medium"

                    reviews.append(SQLReviewResult(
                        file_path=file_path,
                        status="reviewed",
                        issues=issues if isinstance(issues, list) else [str(issues)],
                        optimizations=optimizations if isinstance(optimizations, list) else [str(optimizations)],
                        optimized_sql=optimized_sql,
                        severity=severity
                    ))
                else:
                    reviews.append(SQLReviewResult(
                        file_path=file_path,
                        status="error",
                        issues=["å• Agent ä¼˜åŒ–æœåŠ¡æœªåˆå§‹åŒ–"],
                        severity="medium"
                    ))

            except Exception as e:
                logger.error(f"å• Agent å®¡æ ¸æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
                reviews.append(SQLReviewResult(
                    file_path=file_path,
                    status="error",
                    issues=[f"å• Agent å®¡æ ¸å¤±è´¥: {str(e)}"],
                    severity="high"
                ))

        # æ›´æ–° webhook å†å²è®°å½•
        if webhook_id in webhook_history:
            webhook_history[webhook_id].status = "completed"
            webhook_history[webhook_id].reviews = reviews
            webhook_history[webhook_id].message = f"å• Agent å·²å®Œæˆ {len(reviews)} ä¸ªæ–‡ä»¶çš„å®¡æ ¸"

        # åœ¨ GitHub ä¸Šå‘å¸ƒè¯„è®º
        comment = format_review_comment(reviews)
        await post_github_comment(repo_full_name, commit_sha, comment)

        logger.info(f"å• Agent Webhook {webhook_id} å¤„ç†å®Œæˆ")

    except Exception as e:
        logger.error(f"å• Agent å¤„ç† SQL å®¡æ ¸å¤±è´¥: {e}")
        if webhook_id in webhook_history:
            webhook_history[webhook_id].status = "failed"
            webhook_history[webhook_id].message = f"å• Agent å¤„ç†å¤±è´¥: {str(e)}"

@app.get("/api/webhook/{webhook_id}", response_model=WebhookResponse)
async def get_webhook_status(webhook_id: str):
    """è·å– webhook å¤„ç†çŠ¶æ€"""
    if webhook_id not in webhook_history:
        raise HTTPException(status_code=404, detail="Webhook è®°å½•ä¸å­˜åœ¨")
    
    return webhook_history[webhook_id]

@app.get("/api/webhooks")
async def list_webhooks():
    """åˆ—å‡ºæ‰€æœ‰ webhook å¤„ç†è®°å½•"""
    return {
        "webhooks": list(webhook_history.values()),
        "total": len(webhook_history)
    }

@app.post("/api/batch-optimize")
async def batch_optimize_sql(requests: List[SQLOptimizationRequest]):
    """
    æ‰¹é‡ä¼˜åŒ– SQL æŸ¥è¯¢ - å• Agent æ¶æ„

    æœ€å¤šæ”¯æŒ 10 ä¸ª SQL è¯­å¥çš„æ‰¹é‡ä¼˜åŒ–
    """
    if len(requests) > 10:
        raise HTTPException(status_code=400, detail="æ‰¹é‡è¯·æ±‚æœ€å¤šæ”¯æŒ 10 ä¸ª SQL è¯­å¥")

    if not sql_optimizer_instance:
        raise HTTPException(
            status_code=503,
            detail="SQL ä¼˜åŒ–å™¨æœªåˆå§‹åŒ–ï¼ŒæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        )

    results = []
    start_time = datetime.now()

    for i, request in enumerate(requests):
        try:
            logger.info(f"å• Agent å¤„ç†æ‰¹é‡ä¼˜åŒ– {i+1}/{len(requests)}")

            # å• Agent æ‰§è¡Œå®Œæ•´ä¼˜åŒ–åˆ†æ
            optimization_result = sql_optimizer_instance.optimize_sql(request.sql_query)
            review_result = None  # å• Agent å·²åŒ…å«ç»¼åˆåˆ†æ
            final_status = "OPTIMIZED_BY_SINGLE_AGENT"

            results.append({
                "index": i,
                "status": "success",
                "optimization_result": optimization_result,
                "review_result": review_result,
                "final_status": final_status
            })

        except Exception as e:
            logger.error(f"å• Agent æ‰¹é‡ä¼˜åŒ–ç¬¬ {i+1} ä¸ªå¤±è´¥: {str(e)}")
            results.append({
                "index": i,
                "status": "failed",
                "error": str(e)
            })

    processing_time = (datetime.now() - start_time).total_seconds()

    return {
        "batch_id": str(uuid.uuid4()),
        "total": len(requests),
        "successful": sum(1 for r in results if r["status"] == "success"),
        "failed": sum(1 for r in results if r["status"] == "failed"),
        "processing_time": processing_time,
        "results": results,
        "timestamp": datetime.now().isoformat()
    }

# é”™è¯¯å¤„ç†
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"å…¨å±€å¼‚å¸¸: {str(exc)}")
    return HTTPException(
        status_code=500,
        detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(exc)}"
    )

# å¯åŠ¨å‘½ä»¤æç¤º
if __name__ == "__main__":
    import uvicorn

    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘      SQL ä¼˜åŒ–å®¡æ ¸ç³»ç»Ÿ FastAPI æœåŠ¡ (å• Agent + SSH æ¶æ„)         â•‘
    â•‘                                                                  â•‘
    â•‘  æ¶æ„ç‰¹ç‚¹:                                                       â•‘
    â•‘    â€¢ å•ä¸€ç»¼åˆ SQL ä¸“å®¶ Agent                                      â•‘
    â•‘    â€¢ SSH æ–¹å¼è®¿é—® GitHub (æ›´å®‰å…¨çš„è®¤è¯)                           â•‘
    â•‘    â€¢ ç®€åŒ–çš„å·¥ä½œæµç¨‹ï¼Œé«˜æ•ˆæ‰§è¡Œ                                     â•‘
    â•‘    â€¢ é›†æˆåˆ†æã€ä¼˜åŒ–ã€æŠ¥å‘Šäºä¸€ä½“                                   â•‘
    â•‘                                                                  â•‘
    â•‘  å¯åŠ¨å‘½ä»¤:                                                        â•‘
    â•‘    uvicorn fastapi_service:app --host 0.0.0.0 --port 8004       â•‘
    â•‘                                                                  â•‘
    â•‘  API æ–‡æ¡£:                                                        â•‘
    â•‘    http://localhost:8004/docs                                     â•‘
    â•‘                                                                  â•‘
    â•‘  ä¸»è¦ç«¯ç‚¹:                                                        â•‘
    â•‘    POST /api/optimize          - åŒæ­¥ SQL ä¼˜åŒ– (å• Agent)        â•‘
    â•‘    POST /api/optimize-async    - å¼‚æ­¥ SQL ä¼˜åŒ– (å• Agent)        â•‘
    â•‘    GET  /api/task/{task_id}    - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€                     â•‘
    â•‘    POST /api/batch-optimize    - æ‰¹é‡ SQL ä¼˜åŒ– (å• Agent)        â•‘
    â•‘    POST /api/webhook/gitlab    - GitLab Webhook (SSH å®¡æ ¸)        â•‘
    â•‘    POST /api/webhook/github    - GitHub Webhook å¤‡ç”¨ç«¯ç‚¹          â•‘
    â•‘    GET  /api/webhook/{id}      - æŸ¥è¯¢ webhook çŠ¶æ€               â•‘
    â•‘    GET  /api/health            - å¥åº·æ£€æŸ¥ (å« SSH çŠ¶æ€)           â•‘
    â•‘                                                                  â•‘
    â•‘  ç¯å¢ƒå˜é‡é…ç½®:                                                    â•‘
    â•‘    GITHUB_SSH_KEY_PATH      - SSH ç§é’¥æ–‡ä»¶è·¯å¾„                    â•‘
    â•‘    GITHUB_SSH_KEY_CONTENT   - SSH ç§é’¥å†…å®¹ (å¯é€‰)                 â•‘
    â•‘    GITHUB_USER              - Git ç”¨æˆ·å                          â•‘
    â•‘    GITHUB_EMAIL             - Git é‚®ç®±åœ°å€                        â•‘
    â•‘    GITHUB_WEBHOOK_SECRET    - GitLab Webhook å¯†é’¥ (Token)          â•‘
    â•‘    OPENAI_API_KEY           - LLM API å¯†é’¥                        â•‘
    â•‘    OPENAI_BASE_URL          - LLM åŸºç¡€ URL                        â•‘
    â•‘                                                                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    uvicorn.run(
        "fastapi_service:app",
        host="0.0.0.0",
        port=8004,
        reload=True,
        log_level="info"
    )